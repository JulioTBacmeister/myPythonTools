{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61746a2-46f6-4383-bd6f-a12c72b60998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For package management\n",
    "workdir_ = '/glade/work/juliob/'\n",
    "import sys\n",
    "\n",
    "# The usual\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get some regirdding stuff\n",
    "sys.path.append(workdir_ + 'PyRegridding/Regridder/')\n",
    "import scripGen as SG\n",
    "import esmfmeshGen as emG\n",
    "\n",
    "# Some other useful packages \n",
    "import importlib\n",
    "import esmpy as E\n",
    "\n",
    "# reload dev codes\n",
    "importlib.reload( SG )\n",
    "importlib.reload( emG )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024231f-438a-4bc9-ac3c-791b5bdd7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "import copy\n",
    "\n",
    "def smooth_sst_ndarray_with_boxcar(sst_array , ocn_msk, iterate=1, size=[3,3] ):\n",
    "    \"\"\"\n",
    "    Smooths the SST field using a boxcar filter, replacing land (fill_value) with smoothed values.\n",
    "    \n",
    "    Parameters:\n",
    "    - sst_array: 3D numpy ndarray containing SST data with dimensions (nt, ny, nx)\n",
    "    - fill_value: Value representing land (default is -10)\n",
    "    - size: Size of the boxcar filter window (default is 3x3)\n",
    "\n",
    "    Returns:\n",
    "    - sst_smoothed: 3D ndarray with land values replaced by smoothed SST values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 2: Initialize an array to hold the smoothed results\n",
    "    sst_smoothed = copy.deepcopy(sst_array) #np.empty_like(sst_array)\n",
    "\n",
    "    for nit in np.arange( iterate):\n",
    "        # Loop over time dimension and apply the boxcar filters to each 2D slice\n",
    "        for t in range(sst_array.shape[0]):  # Loop over the time dimension (nt)\n",
    "    \n",
    "            # Step 1: Apply boxcar smoothing along the latitude axis (ny)\n",
    "            sst_lat_smoothed = uniform_filter1d(sst_smoothed[t], size=size[0], axis=0, mode='reflect')\n",
    "            \n",
    "            # Step 2: Apply boxcar smoothing along the longitude axis (nx) with a different boundary treatment\n",
    "            sst_smoothed[t] = uniform_filter1d(sst_lat_smoothed, size=size[1], axis=1, mode='wrap' ) #, cval=cval_lon)\n",
    "        \n",
    "    \n",
    "        sst_smoothed = np.where( ocn_msk == 1, sst_array , sst_smoothed )\n",
    "        print( f\"Iteration={nit}\" )\n",
    "\n",
    "    return sst_smoothed\n",
    "    \n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "def smooth_sst_ndarray_with_boxcar_fast(sst_array, ocn_msk, iterate=1, size=(3,3)):\n",
    "    \"\"\"\n",
    "    Smooths the SST field using a boxcar filter, replacing land with smoothed values.\n",
    "    \n",
    "    Parameters:\n",
    "    - sst_array: 3D numpy ndarray containing SST data with dimensions (nt, ny, nx)\n",
    "    - ocn_msk: 2D numpy array representing the ocean mask (1 for ocean, 0 for land)\n",
    "    - iterate: Number of iterations for smoothing\n",
    "    - size: Size of the boxcar filter window (default is 3x3)\n",
    "\n",
    "    Returns:\n",
    "    - sst_smoothed: 3D ndarray with land values replaced by smoothed SST values.\n",
    "    \"\"\"\n",
    "    # Initialize a copy for smoothing\n",
    "    #sst_smoothed = np.copy(sst_array)\n",
    "    sst_smoothed = copy.deepcopy(sst_array) #np.empty_like(sst_array)\n",
    "\n",
    "    for nit in range(iterate):\n",
    "        # Apply 2D boxcar filter to each time slice (nt, ny, nx)\n",
    "        sst_smoothed = uniform_filter(sst_smoothed, size=(1, *size), mode=('reflect', 'reflect', 'wrap'))\n",
    "        \n",
    "        # Replace land points (ocn_msk == 1) with original SST values\n",
    "        sst_smoothed = np.where(ocn_msk == 1, sst_array, sst_smoothed)\n",
    "        print(f\"Iteration={nit}\")\n",
    "    \n",
    "    return sst_smoothed\n",
    "\n",
    "import cftime\n",
    "import datetime\n",
    "\n",
    "def generate_no_leap_dates(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate a list of cftime.DatetimeNoLeap dates for a no-leap calendar, from start_date to end_date.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    delta = datetime.timedelta(days=1)  # Use the standard datetime timedelta\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        # Move to the next day (using datetime timedelta)\n",
    "        current_date = current_date + delta\n",
    "    \n",
    "    return dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f805aa6-dac2-4af7-b4a6-a955dd525fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Make time, lat, lon coordinates and \n",
    "# time variables\n",
    "#######################################\n",
    "\n",
    "# Step 1: Define the start and end date\n",
    "start_date = cftime.DatetimeNoLeap(2003, 1, 1, 12, 0, 0, has_year_zero=True)\n",
    "end_date = cftime.DatetimeNoLeap(2005, 12, 31, 12, 0, 0, has_year_zero=True)\n",
    "\n",
    "# Step 2: Generate daily dates using cftime\n",
    "cftime_dates = generate_no_leap_dates(start_date, end_date)\n",
    "\n",
    "# Step 3: Create an xarray DataArray with the generated time dimension\n",
    "time_da = xr.DataArray(cftime_dates, dims='time', name='time')\n",
    "\n",
    "# Example usage in a Dataset\n",
    "# Define the latitude and longitude arrays\n",
    "nx , ny = 1440, 720\n",
    "\n",
    "latitudes = np.linspace(-90, 90, ny + 1)  # ny+1 grid points in latitude\n",
    "longitudes = np.linspace(0, 360, nx, endpoint=False)  # nx grid points in longitude, periodic in lon\n",
    "delta_lon = (360.) / nx  # Longitude cell width in radians\n",
    "center_lons = longitudes + 0.5*delta_lon \n",
    "center_lats = 0.5*( latitudes[1:]+latitudes[0:-1] )\n",
    "\n",
    "\n",
    "ds = xr.Dataset(\n",
    "    coords={\n",
    "        'time': time_da,\n",
    "        'lat': center_lats,\n",
    "        'lon': center_lons\n",
    "    }\n",
    ")\n",
    "\n",
    "#######################\n",
    "print(len( ds.time ) )\n",
    "\n",
    "ntimes=len( ds.time ) \n",
    "date = np.zeros( ntimes, dtype=np.int32 )\n",
    "datesec = np.zeros( ntimes, dtype=np.int32 )\n",
    "\n",
    "for n in np.arange( ntimes ):\n",
    "    date[n] = 10_000*ds.time[n].item().year+100*ds.time[n].item().month+ds.time[n].item().day\n",
    "    datesec[n] = 3_600*ds.time[n].item().hour\n",
    "\n",
    "ds['date'] = xr.DataArray( date.astype(np.int32) ,\n",
    "                             dims=('time',)) \n",
    "ds['datesec'] = xr.DataArray( datesec.astype(np.int32) ,\n",
    "                             dims=('time',)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148e41f-494f-4cb5-b19d-d120ed2bfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dcbc1-eda6-4ee6-b40c-822f7467f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#   \n",
    "####\n",
    "files=['/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/sst.day.mean.2003.nc', '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/sst.day.mean.2004.nc', '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/sst.day.mean.2005.nc' ]\n",
    "\n",
    "SST=xr.open_mfdataset(files, concat_dim='time', combine='nested' )\n",
    "# Remove February 29, 2004\n",
    "SST = SST.sel(time=~((SST['time.month'] == 2) & (SST['time.day'] == 29) & (SST['time.year'] == 2004)))\n",
    "\n",
    "sstnan=SST.sst.values\n",
    "\n",
    "SST_zer=SST.fillna( 0.)\n",
    "\n",
    "sstv=SST_zer.sst.values\n",
    "nt,ny,nx=np.shape( sstv )\n",
    "\n",
    "sstZon=np.nanmean( sstnan, axis=2 )\n",
    "sstZonX=np.expand_dims( sstZon, axis=2)\n",
    "sstZonX= np.repeat( sstZonX, nx , axis=2)\n",
    "\n",
    "\n",
    "sstFill = np.where(np.isnan(sstnan), sstZonX , sstv)\n",
    "sstFill = np.where(np.isnan(sstFill), 0. , sstFill)\n",
    "\n",
    "ocn_msk = np.where(np.isnan(sstnan), 0. , 1. )\n",
    "\n",
    "\n",
    "sstFillSm = smooth_sst_ndarray_with_boxcar(sstFill , ocn_msk, iterate=10, size=[17,17] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd73de8-ac4e-405f-b702-39b9ef18126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf( (sstFillSm)[360,:,:], levels=np.linspace(-10,40,num=51) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533bdf7f-a754-4e62-9e96-77d4120f984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \n",
    "####\n",
    "files=['/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/icec.day.mean.2003.nc', '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/icec.day.mean.2004.nc', '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/icec.day.mean.2005.nc' ]\n",
    "\n",
    "ICE=xr.open_mfdataset(files, concat_dim='time', combine='nested' )\n",
    "# Remove February 29, 2004\n",
    "ICE = ICE.sel(time=~((ICE['time.month'] == 2) & (ICE['time.day'] == 29) & (ICE['time.year'] == 2004)))\n",
    "\n",
    "icenan=ICE.icec.values\n",
    "\n",
    "ICE_zer=ICE.fillna( 0.)\n",
    "icev=ICE_zer.icec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc3790-9e84-43a3-ac47-86861d31c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Add SST and ice_cover\n",
    "################################\n",
    "\n",
    "ds['SST_cpl'] = xr.DataArray( sstFillSm.astype(np.float32) ,\n",
    "                             dims=('time','lat','lon',)) \n",
    "ds['ice_cov'] = xr.DataArray( icev.astype(np.float32) ,\n",
    "                             dims=('time','lat','lon',)) \n",
    "\n",
    "\n",
    "ds.to_netcdf( '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/sst_ice_NOAA_QxQ_2003_2005.nc' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7c7a7-e72b-46b9-a835-979aec360760",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesh=emG.nxny_to_mesh( nx=nx, ny=ny, mesh_file_out='test-mesh.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d749c-7a8f-4b77-a337-cf2df83172e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesh.to_netcdf( '/glade/campaign/cgd/amp/juliob/NOAA_OI_SST/sst_ice_NOAA_QxQ_ESMFmesh.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b26f66-af8b-4ebd-ad41-a8407191fbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
